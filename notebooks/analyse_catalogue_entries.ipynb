{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531c846c",
   "metadata": {},
   "source": [
    "# Extracted Catalogue Entry Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf50aac",
   "metadata": {},
   "source": [
    "Analyse catalogue entries extracted by main.py or extract_catalogue_entries.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import src.data.xml_extraction as xmle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\\split_data\\BMC_[0-9]*\\catalogue_entries.csv\"\n",
    "entry_csv_paths = glob.glob(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a6217",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_csvs = {p.split(\"\\\\\")[-2]: pd.read_csv(p, converters={\"entry\": lambda x: x[2:-2].split(\"\\', \\'\")}) for p in entry_csv_paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vol, df in entry_csvs.items():\n",
    "    df[\"vol\"] = int(vol.split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry_no_caps_df = pd.concat(list(entry_csvs.values())).rename_axis(index=\"volume_entry_num\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c6563",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df = pd.concat(list(entry_csvs.values())).rename_axis(index=\"volume_entry_num\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49064bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16662982",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\\split_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(1,11):\n",
    "#     old = os.path.join(root, f\"BMC_{x}\\combinedrawtext_single_line_old_process.txt\")\n",
    "#     new = os.path.join(root, f\"BMC_{x}\\combinedrawtext_single_line_v1.0.txt\")\n",
    "#     os.rename(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebd53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entry_df.to_csv(os.path.join(root, \"all_volume_catalogue_entries.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(1,11):\n",
    "#     out_name = os.path.join(root, f\"BMC_{x}\\combinedrawtext_single_line_v1.1.txt\")\n",
    "#     vol_df = entry_df.query(\"vol == @x\")\n",
    "#     with open(out_name, \"w\", encoding=\"utf-8\") as f:\n",
    "#         grpby = vol_df.groupby(by=\"volume_entry_num\")\n",
    "#         for grp in grpby:\n",
    "#             f.write(grp[1][\"entry_text\"].values[0].replace(\"\\n\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7576fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = entry_df[\"entry\"].progress_apply(lambda x: xmle.split_by_language(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"split.p\", \"wb\") as f:\n",
    "#     pickle.dump(split, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bda11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df[\"split_text\"] = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7476e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df[\"split_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042b895",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = entry_df.query(\"vol == 1\").groupby(by=\"volume_entry_num\")[\"split_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b26a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1,11):\n",
    "    out_name = os.path.join(root, f\"BMC_{x}\\combinedsplittext_single_line_v1.1.txt\")\n",
    "    vol_df = entry_df.query(\"vol == @x\")\n",
    "\n",
    "    grpby = vol_df.groupby(by=\"volume_entry_num\")[\"split_text\"]\n",
    "    \n",
    "    vol_split_txt = \"\"\n",
    "    \n",
    "    for grp in grpby:\n",
    "        entry_txt = \"\"\n",
    "        language_en = grp[1].values[0][0]\n",
    "        lang_grpd_entry_lines = grp[1].values[0][1]\n",
    "        start = 0 + int(not language_en)\n",
    "        for lang_grp in lang_grpd_entry_lines[start::2]:\n",
    "            for line in lang_grp:\n",
    "                entry_txt += line.replace(\"\\n\", \" \").replace('\"', \"\").replace(\"'\", \"\") + \" \"\n",
    "        vol_split_txt += entry_txt + \"\\n\"\n",
    "\n",
    "    with open(out_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(vol_split_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_no_caps_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e023f1",
   "metadata": {},
   "source": [
    "## Entry length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.loc[0, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ac330",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(entry_df.loc[0, \"entry_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df[\"entry_length\"] = entry_df[\"entry_text\"].transform(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c548a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.loc[0, \"entry_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39611208",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = entry_df[\"entry_length\"].rolling(window=100, center=True).mean()\n",
    "mean = entry_df.groupby(by=\"vol\")[\"entry_length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076991c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe923d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean.rename_axis(\"Volume\").rename(\"Mean Entry Length\").to_csv(\"..\\\\data\\\\processed\\\\mean_lengths.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af9cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_entrys = entry_df.groupby(by=\"vol\")[\"vol\"].count()\n",
    "n_entrys.loc[0] = 0\n",
    "n_entrys.sort_index(inplace=True)\n",
    "x_locs = n_entrys.cumsum() - n_entrys.cumsum().diff()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106bec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(entry_df[\"entry_length\"], lw=1)\n",
    "ax.plot(ma, \"black\", label=\"Moving average\")\n",
    "ax.set_title(\"Catalogue Entry Length For Incunabula Volumes 1-10\", fontsize='x-large')\n",
    "ax.set_xlabel(\"Catalogue Entry Number (across all volumes)\", fontsize='x-large')\n",
    "ax.set_ylabel(\"Entry length (characters)\", fontsize='x-large')\n",
    "ax.tick_params(labelsize='large')\n",
    "ax.vlines(n_entrys.cumsum(), 0, ax.get_ylim()[1], colors=\"black\", linestyles=\"--\")\n",
    "ax.set_xlim(0, len(entry_df))\n",
    "ax.set_ylim(0, entry_df[\"entry_length\"].max() + 100)\n",
    "for i, x in enumerate(x_locs.dropna()[:8]):\n",
    "    ax.text(x, 10600, f\"BMC {i+1}\\n$\\mu$: {mean.loc[i+1]:.0f}\", ha=\"center\")\n",
    "    \n",
    "\n",
    "ax.text(x_locs[9], 10600, f\"BMC {9}\", rotation=\"vertical\", ha=\"center\")\n",
    "ax.text(x_locs[10], 10600, f\"BMC {10}\", rotation=\"vertical\", ha=\"center\")\n",
    "ax.text(x_locs[9], 9100, f\"$\\mu$: {mean.loc[9]:.0f}\", rotation=\"vertical\", ha=\"center\")\n",
    "ax.text(x_locs[10], 9100, f\"$\\mu$: {mean.loc[10]:.0f}\", rotation=\"vertical\", ha=\"center\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6384fe",
   "metadata": {},
   "source": [
    "Vol 5 and 8 were catalogued by the same person, so poss more errors here or actually reflecting cataloguing style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.query(\"entry_length > 6000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.savefig(\"..\\\\reports\\\\figures\\\\entry_length.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1189050",
   "metadata": {},
   "source": [
    "## Another copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_another_copy(row):\n",
    "    \"\"\"\n",
    "\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    another_variants = [\n",
    "        'Another cancelled',\n",
    "        'A cancelled',\n",
    "        'Another copy',\n",
    "        'Another edition',\n",
    "        'Another fragment,',\n",
    "        'Another issue'\n",
    "    ]\n",
    "    \n",
    "    match = []\n",
    "    for v in another_variants:\n",
    "        p = re.compile(v)\n",
    "        m = p.finditer(row)\n",
    "        if m:\n",
    "            match += m\n",
    "    \n",
    "    if match:\n",
    "        return match\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdfaa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to find valid variants of another copy\n",
    "\"\"\"\n",
    "copy_re = re.compile(\"Another \\S*\")\n",
    "anothers = entry_df[\"entry_text\"].apply(lambda x: copy_re.search(x))\n",
    "copy_variants = sorted(list(set(anothers.apply(lambda x: x.group() if x else None).dropna())))\n",
    "copy_variants\n",
    "\n",
    "entry_df[\"match\"] = entry_df[\"entry_text\"].apply(lambda x: copy_re.search(x))\n",
    "entry_df[\"preceding_shelfmark\"] = entry_df.apply(check_for_leading_shelfmark, axis=1)\n",
    "\n",
    "x = 2\n",
    "print(copy_variants[x])\n",
    "entry_df[entry_df[\"entry_text\"].str.contains(copy_variants[x])]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c838c5f",
   "metadata": {},
   "source": [
    "All the matches of the \"Another \\S*\" regex with statement as to whether consists of actual 'Another edition' information.\n",
    "\n",
    "\n",
    "'Another (crown':  Not valid, referring to watermarks in the text  \n",
    "'Another calendar':  Not valid, referring to calendars in the work  \n",
    "'Another calligraphic':  Not valid, referring to calligraphic letters  \n",
    "'Another cancelled':  Valid, has it's own Proctor # and copy specific info. There's also a copy before this that's just \"A cancelled copy\", but there's only one occurence of this.  \n",
    "'A cancelled': Valid, see above entry.  \n",
    "'Another closely':  Not valid, describes another edition that's similar  \n",
    "'Another compartment':  Not valid, part of the information rather than about another copy  \n",
    "'Another copy':  Valid  \n",
    "'Another copy,':  Subset of Another copy  \n",
    "'Another copy.':  Subset of Another copy  \n",
    "'Another cut':  Not valid  \n",
    "'Another edition':  Valid  \n",
    "'Another edition,':  Subset  \n",
    "'Another edition.':  Subset  \n",
    "'Another fragment,':  Valid  \n",
    "'Another full-page':  Not valid  \n",
    "'Another issue':  Valid  \n",
    "'Another issue,':  Subset  \n",
    "'Another issue.':  Subset  \n",
    "'Another metrical':  Not valid  \n",
    "'Another reading.':  Not valid  \n",
    "'Another recension':  Not valid  \n",
    "'Another setting':  Not valid  \n",
    "'Another setting-up':  Subset  \n",
    "'Another version:  Not valid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e272db",
   "metadata": {},
   "outputs": [],
   "source": [
    "another_variants = [\n",
    "    'Another cancelled',\n",
    "    'A cancelled',\n",
    "    'Another copy',\n",
    "    'Another edition',\n",
    "    'Another fragment,',\n",
    "    'Another issue'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57adeb7",
   "metadata": {},
   "source": [
    "Having a leading shelfmark is highly indicative of an 'Another copy' entry actually being another copy. Of course this relies on the shelfmark detection being accurate. In some cases this isn't so, see analysis below for efforts to improve Issac's shelfmark finding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf119b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO some of the shelfmarks are absent - instead the Another copy has it's location listed as \"Print room\"\n",
    "# work out what to do with this\n",
    "\n",
    "def check_for_leading_shelfmark(row, match_col, find_valid=True):\n",
    "    shelfmark = False\n",
    "    valid_matches = []\n",
    "    if row[match_col]:\n",
    "        valid = [xmle.find_title_shelfmark(row[\"entry_text\"][match.span()[0]-100: match.span()[1]]) for match in row[match_col]]\n",
    "        if not find_valid:\n",
    "            valid = [not v for v in valid]\n",
    "        valid_matches = [m for m, v in zip(row[match_col], valid) if v] \n",
    "    if valid_matches:\n",
    "        return valid_matches\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980750c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df[\"other_copies\"] = entry_df[\"entry_text\"].apply(lambda x: extract_another_copy(x))\n",
    "entry_df[\"valid_copies\"] = entry_df.apply(check_for_leading_shelfmark, match_col=\"other_copies\", axis=1)\n",
    "entry_df[\"bad_copies\"] = entry_df.apply(check_for_leading_shelfmark, match_col=\"other_copies\", find_valid=False, axis=1)\n",
    "entry_df[\"leading_caps\"] = entry_df[\"entry_text\"].apply(lambda x: caps_regex.match(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_regex = re.compile(\"[A-Z][A-Z](?!I)[A-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "entry_no_caps_df.loc[idx, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac1bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.loc[idx, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_regex.search(entry_df.loc[idx, \"entry_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7948d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.loc[idx, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39670d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vol = entry_df.loc[idx, \"vol\"]\n",
    "col = int(entry_df.loc[idx, \"xml\"][-1])\n",
    "jpg = entry_df.loc[idx, \"xml\"][:-2]\n",
    "image_path = glob.glob(\n",
    "    r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "    f\"\\\\BMC_{vol} {col} column pages Transkribus export\"\n",
    "    f\"\\\\*\\\\*\\\\*{jpg}.jpg\"\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a9a72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attempts = 0\n",
    "while attempts < 10:\n",
    "    try:\n",
    "        display(Image(filename=image_path))\n",
    "        break\n",
    "    except:\n",
    "        attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    next_jpg = jpg[:-1] + str(int(jpg[-1]) + 1)\n",
    "    next_image_path = glob.glob(\n",
    "        r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "        f\"\\\\BMC_{vol} {col} column pages Transkribus export\"\n",
    "        f\"\\\\*\\\\*\\\\*{next_jpg}.jpg\"\n",
    "    )[0]\n",
    "    \n",
    "except IndexError:\n",
    "    next_jpg = jpg[:-1] + str(int(jpg[-1]) + 1)\n",
    "    if int(col) == 2:\n",
    "        next_col = 4\n",
    "    elif int(col) == 4:\n",
    "        next_col = 2\n",
    "    next_image_path = glob.glob(\n",
    "        r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "        f\"\\\\BMC_{vol} {next_col} column pages Transkribus export\"\n",
    "        f\"\\\\*\\\\*\\\\*{next_jpg}.jpg\"\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08607483",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attempts = 0\n",
    "while attempts < 10:\n",
    "    try:\n",
    "        display(Image(filename=next_image_path))\n",
    "        break\n",
    "    except:\n",
    "        attempts += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951effa",
   "metadata": {},
   "source": [
    "### Assess regex variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bd8a5",
   "metadata": {},
   "source": [
    "Some of the 'another copy' leading shelfmarks aren't being picked up. Improve the original shelfmark detection, particularly C numbers (which are sometimes '1' numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "caps_regex = re.compile(\"[A-Z]{3,}\")\n",
    "# c_num_regex = re.compile(\"[^I]C\\\\.[0-9]\")  # C number title references\n",
    "# c_num_space_regex = re.compile(\"[^I]C\\\\.[ ]?[0-9]\")  # C number title references\n",
    "c_num_regex = re.compile(\"[^A-Za-z0-9\\\\n\\.\\-\\u201C]C\\\\.[ ]?[0-9]\")  # C number title references\n",
    "c_date_regex = re.compile(\"[^I]C\\\\.[ \\t\\r\\f\\v]?1[0-9]{3}[^0-9]\")  # accidental date references\n",
    "one_num_regex = re.compile(\"1\\\\.\\\\s[a-z]\")\n",
    "g_num_regex = re.compile(\"G.[ ]?[0-9]\")\n",
    "i_num_regex = re.compile(r\"[I1][ABC]\\\\.[ ]?[0-9]\")  # I number title references\n",
    "date_regex = re.compile(\"1[45][0-9][0-9]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_nums = entry_df[\"entry_text\"].apply(lambda x: c_num_regex.finditer(x)).apply(lambda x: [x for x in x]).apply(lambda x: x if len(x) > 0 else None)\n",
    "c_dates = entry_df[\"entry_text\"].apply(lambda x: c_date_regex.finditer(x)).apply(lambda x: [x for x in x]).apply(lambda x: x if len(x) > 0 else None)\n",
    "\n",
    "entry_df[\"c_nums\"] = c_nums\n",
    "entry_df[\"c_dates\"] = c_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_date_matches(row):\n",
    "    if row[\"c_dates\"] and row[\"c_nums\"]:\n",
    "        for r in row[\"c_dates\"]:\n",
    "            date_span = set(range(*r.span()))\n",
    "            accidental_date = [date_span.intersection(set(range(*x.span()))) for x in row[\"c_nums\"]]\n",
    "            \n",
    "        clean_cnums = [x for x,y in zip(row[\"c_nums\"], accidental_date) if not y]\n",
    "        if clean_cnums:\n",
    "            return clean_cnums\n",
    "        else:\n",
    "            return row[\"c_nums\"]\n",
    "    else:\n",
    "        return row[\"c_nums\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd4cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df[\"clean_c_nums\"] = entry_df.apply(exclude_date_matches, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_idx = entry_df[\"clean_cnums\"].dropna().apply(lambda x: [x.span() for x in x]).index.difference(entry_df[\"let_cnums\"].dropna().apply(lambda x: [x.span() for x in x]).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(row, match_row):\n",
    "    matches = []\n",
    "    if not row[match_row]:\n",
    "        return None\n",
    "    for match in row[match_row]:\n",
    "        matches.append(row[\"entry_text\"][match.span()[0]:match.span()[1] + 20])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea4859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "def twenty_plus_gen():\n",
    "    global i\n",
    "    i += 10\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21933e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_df.apply(find_matches, match_row=\"clean_c_nums\", axis=1).dropna().iloc[twenty_plus_gen()-10: twenty_plus_gen()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49a1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = 4767\n",
    "entry_df.loc[idx, \"entry_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b53423",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = entry_df.loc[idx, \"vol\"]\n",
    "col = int(entry_df.loc[idx, \"xml\"][-1])\n",
    "jpg = entry_df.loc[idx, \"xml\"][:-2]\n",
    "image_path = glob.glob(\n",
    "    r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "    f\"\\\\BMC_{vol} {col} column pages Transkribus export\"\n",
    "    f\"\\\\*\\\\*\\\\*{jpg}.jpg\"\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = 0\n",
    "while attempts < 10:\n",
    "    try:\n",
    "        display(Image(filename=image_path))\n",
    "        break\n",
    "    except:\n",
    "        attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b573e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    next_jpg = jpg[:-1] + str(int(jpg[-1]) + 1)\n",
    "    next_image_path = glob.glob(\n",
    "        r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "        f\"\\\\BMC_{vol} {col} column pages Transkribus export\"\n",
    "        f\"\\\\*\\\\*\\\\*{next_jpg}.jpg\"\n",
    "    )[0]\n",
    "    \n",
    "except IndexError:\n",
    "    next_jpg = jpg[:-1] + str(int(jpg[-1]) + 1)\n",
    "    if int(col) == 2:\n",
    "        next_col == 4\n",
    "    elif int(col) == 4:\n",
    "        next_col == 2\n",
    "    next_image_path = glob.glob(\n",
    "        r\"\\\\ad\\collections\\TwoCenturies\\TwoCenturies IV\\Incunabula\"\n",
    "        f\"\\\\BMC_{vol} {next_col} column pages Transkribus export\"\n",
    "        f\"\\\\*\\\\*\\\\*{next_jpg}.jpg\"\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16e7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = 0\n",
    "while attempts < 10:\n",
    "    try:\n",
    "        display(Image(filename=next_image_path))\n",
    "        break\n",
    "    except:\n",
    "        attempts += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea126cca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:incu]",
   "language": "python",
   "name": "conda-env-incu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
